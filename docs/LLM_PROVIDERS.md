# Configuration des Providers LLM

L'agent IA supporte plusieurs providers LLM pour vous offrir une flexibilitÃ© maximale entre modÃ¨les locaux et cloud.

## Providers SupportÃ©s

### 1. ğŸ  Ollama (Local - Par dÃ©faut)

**Avantages:**
- âœ… Gratuit et privÃ©
- âœ… Pas de coÃ»t API
- âœ… Fonctionne hors ligne
- âœ… DonnÃ©es restent locales

**InconvÃ©nients:**
- âš ï¸ NÃ©cessite ressources locales (2-4GB RAM)
- âš ï¸ Moins puissant que GPT-4 ou Claude

**Configuration:**

```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=phi3:mini
```

**Installation:**

```bash
# 1. Installer Ollama
# Windows: https://ollama.ai/download/windows
# Mac: brew install ollama
# Linux: curl -fsSL https://ollama.ai/install.sh | sh

# 2. TÃ©lÃ©charger un modÃ¨le
ollama pull phi3:mini        # ~2GB, recommandÃ© (lÃ©ger)
ollama pull llama3:8b        # ~5GB, plus performant
ollama pull mistral:7b       # ~4GB, Ã©quilibrÃ©
ollama pull codellama:7b     # ~4GB, spÃ©cialisÃ© code

# 3. Lancer le serveur
ollama serve
```

**ModÃ¨les recommandÃ©s:**
- `phi3:mini` - LÃ©ger (2GB), bon pour 8GB RAM
- `llama3:8b` - Performant (5GB), pour 16GB+ RAM
- `codellama:7b` - SpÃ©cialisÃ© code
- `mixtral:8x7b` - TrÃ¨s performant (26GB), pour 32GB+ RAM

---

### 2. ğŸ¤– OpenAI (ChatGPT)

**Avantages:**
- âœ… TrÃ¨s performant (GPT-4, GPT-4 Turbo)
- âœ… Pas de ressources locales requises
- âœ… API rapide et fiable

**InconvÃ©nients:**
- ğŸ’° Payant (~$0.01-0.03 par 1K tokens)
- ğŸŒ NÃ©cessite connexion internet
- ğŸ“Š DonnÃ©es envoyÃ©es Ã  OpenAI

**Configuration:**

```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_BASE_URL=https://api.openai.com/v1  # Optionnel
```

**Obtenir une clÃ© API:**

1. CrÃ©er un compte sur https://platform.openai.com
2. Aller dans "API Keys"
3. CrÃ©er une nouvelle clÃ© secrÃ¨te
4. Ajouter des crÃ©dits (minimum $5)

**ModÃ¨les disponibles:**

| ModÃ¨le | Prix (1M tokens) | Usage recommandÃ© |
|--------|------------------|------------------|
| `gpt-3.5-turbo` | $0.50 / $1.50 | TÃ¢ches simples, Budget |
| `gpt-4-turbo-preview` | $10 / $30 | Ã‰quilibrÃ© performance/coÃ»t |
| `gpt-4` | $30 / $60 | Maximum de qualitÃ© |
| `gpt-4o` | $5 / $15 | Nouveau, rapide et Ã©conomique |

**Estimation de coÃ»t:**

- TÃ¢che simple (crÃ©er API) : ~10K tokens = $0.10-0.30
- Projet complet (React app) : ~50K tokens = $0.50-1.50
- DÃ©veloppement complexe : ~500K tokens = $5-15

---

### 3. ğŸ§  Claude (Anthropic)

**Avantages:**
- âœ… Excellent pour le code et raisonnement
- âœ… TrÃ¨s bon en analyse et dÃ©composition
- âœ… Moins de censure que GPT-4

**InconvÃ©nients:**
- ğŸ’° Payant (~$0.008-0.024 par 1K tokens)
- ğŸŒ NÃ©cessite connexion internet
- âš ï¸ Utilise l'ancienne API Completions (Claude 2.x)

**Configuration:**

```env
LLM_PROVIDER=claude
CLAUDE_API_KEY=sk-ant-api03-...
CLAUDE_MODEL=claude-2.1
```

**Obtenir une clÃ© API:**

1. CrÃ©er un compte sur https://console.anthropic.com
2. Aller dans "API Keys"
3. CrÃ©er une nouvelle clÃ©
4. Ajouter des crÃ©dits

**ModÃ¨les disponibles (API Completions):**

| ModÃ¨le | Prix (1M tokens) | Usage recommandÃ© |
|--------|------------------|------------------|
| `claude-instant-1.2` | $0.80 / $2.40 | Rapide, Ã©conomique |
| `claude-2.0` | $8 / $24 | Ã‰quilibrÃ© |
| `claude-2.1` | $8 / $24 | **RECOMMANDÃ‰** - AmÃ©liorÃ© |

**Note:** Cette version utilise l'API Completions (Claude 2.x). Pour utiliser Claude 3.5 Sonnet et l'API Messages (nouvelle gÃ©nÃ©ration), une mise Ã  jour du SDK sera nÃ©cessaire dans une version future.

**Pourquoi choisir Claude:**
- ğŸ¯ Excellent pour architecture et planification
- ğŸ“ TrÃ¨s bon pour gÃ©nÃ©rer du code
- ğŸ” Bon en analyse de code existant

---

### 4. â˜ï¸ Azure OpenAI

**Avantages:**
- âœ… Entreprise (SLA, support)
- âœ… Compliance (RGPD, SOC2)
- âœ… DÃ©ploiement privÃ© possible

**InconvÃ©nients:**
- ğŸ’° CoÃ»t entreprise
- ğŸ”§ Configuration complexe

**Configuration:**

```env
LLM_PROVIDER=azure
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=gpt-4
```

**Mise en place:**

1. CrÃ©er une ressource Azure OpenAI
2. DÃ©ployer un modÃ¨le
3. RÃ©cupÃ©rer endpoint et clÃ© API

---

## ğŸ¯ Quel Provider Choisir ?

### Pour dÃ©buter / DÃ©veloppement local
```
âœ… Ollama (phi3:mini ou llama3)
```
- Gratuit, privÃ©, rapide Ã  setup
- Parfait pour apprendre et tester

### Pour usage budgÃ©tÃ©
```
âœ… OpenAI GPT-3.5-Turbo ou GPT-4o
```
- Bon rapport qualitÃ©/prix
- $5-20/mois pour usage normal

### Pour meilleure qualitÃ©
```
âœ… Claude 3.5 Sonnet ou GPT-4 Turbo
```
- Excellent pour projets complexes
- Meilleure comprÃ©hension du contexte

### Pour entreprise
```
âœ… Azure OpenAI
```
- SLA, support, compliance
- DÃ©ploiement privÃ©

---

## ğŸ”€ Changer de Provider Dynamiquement

Vous pouvez changer de provider Ã  tout moment:

```bash
# Dans .env
LLM_PROVIDER=claude  # ou openai, ollama, azure

# RedÃ©marrer l'agent
npm run dev
```

**Via code (avancÃ©):**

```typescript
import { llm } from './src/core/llm.js';

// Changer vers OpenAI
llm.setProvider('openai', 'gpt-4-turbo-preview');

// Changer vers Claude
llm.setProvider('claude', 'claude-2.1');

// Changer vers Ollama
llm.setProvider('ollama', 'llama3:8b');
```

---

## ğŸ’¡ Bonnes Pratiques

### 1. **DÃ©veloppement â†’ Local, Production â†’ Cloud**

```env
# .env.development
LLM_PROVIDER=ollama
OLLAMA_MODEL=phi3:mini

# .env.production
LLM_PROVIDER=claude
CLAUDE_MODEL=claude-3-5-sonnet-20241022
```

### 2. **TÃ¢ches Simples â†’ ModÃ¨le LÃ©ger**

Pour tÃ¢ches rÃ©pÃ©titives ou simples:
- Ollama `phi3:mini`
- OpenAI `gpt-3.5-turbo`
- Claude `haiku`

### 3. **TÃ¢ches Complexes â†’ ModÃ¨le Puissant**

Pour architecture, refactoring, analyse:
- OpenAI `gpt-4-turbo-preview`
- Claude `claude-3-5-sonnet-20241022`
- Ollama `mixtral:8x7b` (si 32GB+ RAM)

### 4. **Monitoring des CoÃ»ts**

```typescript
import { llm } from './src/core/llm.js';

// Obtenir info provider
const info = llm.getProviderInfo();
console.log(`Provider: ${info.provider}, Model: ${info.model}`);

// VÃ©rifier disponibilitÃ© avant utilisation
if (await llm.isModelAvailable()) {
  console.log('âœ… ModÃ¨le prÃªt');
} else {
  console.log('âŒ ModÃ¨le indisponible');
}
```

---

## ğŸ› Troubleshooting

### Ollama: "Connection refused"

```bash
# VÃ©rifier que le serveur tourne
ollama serve

# Tester
curl http://localhost:11434/api/tags
```

### OpenAI: "Invalid API key"

```bash
# VÃ©rifier variable d'environnement
echo $OPENAI_API_KEY

# Tester clÃ© API
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### Claude: "Rate limit exceeded"

- Attendre 1 minute
- VÃ©rifier quota sur console.anthropic.com
- Passer Ã  un tier supÃ©rieur

### Erreur gÃ©nÃ©rale

```bash
# VÃ©rifier les logs
npm run cli logs

# Tester disponibilitÃ©
npm run cli check-model
```

---

## ğŸ“Š Comparaison ComplÃ¨te

| CritÃ¨re | Ollama | OpenAI GPT-4 | Claude 2.1 | Azure |
|---------|--------|--------------|------------|-------|
| **CoÃ»t** | ğŸŸ¢ Gratuit | ğŸŸ¡ Moyen | ğŸŸ¡ Moyen | ğŸ”´ Ã‰levÃ© |
| **Performance** | ğŸŸ¡ Bon | ğŸŸ¢ Excellent | ğŸŸ¢ TrÃ¨s bon | ğŸŸ¢ Excellent |
| **PrivacitÃ©** | ğŸŸ¢ Total | ğŸ”´ Cloud | ğŸ”´ Cloud | ğŸŸ¡ Configurable |
| **Setup** | ğŸŸ¢ Simple | ğŸŸ¢ Simple | ğŸŸ¢ Simple | ğŸ”´ Complexe |
| **Hors-ligne** | ğŸŸ¢ Oui | ğŸ”´ Non | ğŸ”´ Non | ğŸ”´ Non |
| **Code** | ğŸŸ¡ Bon | ğŸŸ¢ Excellent | ğŸŸ¢ TrÃ¨s bon | ğŸŸ¢ Excellent |
| **Contexte** | ğŸŸ¡ 4-8K | ğŸŸ¢ 128K | ğŸŸ¢ 100K | ğŸŸ¢ 128K |

---

## ğŸš€ Exemples d'Usage

### Exemple 1: Ollama pour dÃ©veloppement local

```env
LLM_PROVIDER=ollama
OLLAMA_MODEL=phi3:mini
```

```bash
npm run dev
# Via WhatsApp: "CrÃ©e une API Express simple"
```

### Exemple 2: GPT-4 pour projet important

```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4-turbo-preview
```

```bash
npm run dev
# Via WhatsApp: "DÃ©veloppe une application React complÃ¨te avec authentification"
```

### Exemple 3: Claude 2.1 pour analyse de code

```env
LLM_PROVIDER=claude
CLAUDE_API_KEY=sk-ant-...
CLAUDE_MODEL=claude-2.1
```

```bash
npm run dev
# Via WhatsApp: "Analyse mon projet et suggÃ¨re des amÃ©liorations d'architecture"
```

---

## ğŸ”— Ressources

**Ollama:**
- Site: https://ollama.ai
- ModÃ¨les: https://ollama.ai/library
- GitHub: https://github.com/ollama/ollama

**OpenAI:**
- Platform: https://platform.openai.com
- Pricing: https://openai.com/pricing
- Docs: https://platform.openai.com/docs

**Claude (Anthropic):**
- Console: https://console.anthropic.com
- Pricing: https://www.anthropic.com/pricing
- Docs: https://docs.anthropic.com

**Azure OpenAI:**
- Portal: https://portal.azure.com
- Docs: https://learn.microsoft.com/azure/ai-services/openai/
