# ğŸš€ Guide de DÃ©marrage Rapide - AutoAgent IA

DÃ©marrez avec AutoAgent IA en 5 minutes!

## âš¡ Installation Express

### 1. Choisir votre Provider LLM

#### Option A: Ollama (Local - Gratuit) ğŸ 

Installez Ollama:
- **macOS/Linux:** `curl https://ollama.ai/install.sh | sh`
- **Windows:** TÃ©lÃ©chargez depuis https://ollama.ai

Puis tÃ©lÃ©chargez un modÃ¨le:
```bash
ollama pull phi3:mini  # LÃ©ger (2GB) - RecommandÃ© pour 8GB RAM
# ou
ollama pull llama3:8b  # Plus performant (5GB) - Pour 16GB+ RAM
```

Dans `.env`:
```env
LLM_PROVIDER=ollama
OLLAMA_MODEL=phi3:mini
```

#### Option B: OpenAI GPT-4 (Cloud - Payant) ğŸ¤–

1. Obtenez une clÃ© API: https://platform.openai.com
2. Ajoutez $5-20 de crÃ©dits

Dans `.env`:
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4-turbo-preview
```

#### Option C: Claude (Cloud - Payant) ğŸ§ 

1. Obtenez une clÃ© API: https://console.anthropic.com
2. Ajoutez des crÃ©dits

Dans `.env`:
```env
LLM_PROVIDER=claude
CLAUDE_API_KEY=sk-ant-...
CLAUDE_MODEL=claude-2.1
```

**Note:** Utilise Claude 2.x (ancienne API). Pour Claude 3.5, une mise Ã  jour future du SDK sera nÃ©cessaire.

ğŸ“– **[Guide complet des providers](docs/LLM_PROVIDERS.md)**

### 2. Setup du Projet

```bash
# Installer les dÃ©pendances
npm install

# Configurer
npm run setup
cp .env.example .env

# Ã‰diter .env avec votre provider choisi
nano .env
```

### 3. Premier Lancement

```bash
# DÃ©marrer l'agent
npm run dev
```

### 4. Scanner le QR Code (optionnel)

Si WhatsApp est activÃ©, scannez le QR code qui s'affiche:
1. Ouvrez WhatsApp sur votre tÃ©lÃ©phone
2. Menu â†’ Appareils connectÃ©s â†’ Connecter un appareil
3. Scannez le QR code

## ğŸ“± Test via WhatsApp

Envoyez Ã  l'agent:
```
status
```

Vous devriez recevoir:
```
ğŸ“Š Statut de l'Agent

âœ… TÃ¢ches complÃ©tÃ©es: 0
â³ En cours: 0
ğŸ“‹ En attente: 0

ğŸ’¾ Total: 0 tÃ¢ches
```

## ğŸ¯ PremiÃ¨re TÃ¢che

### Via WhatsApp

Envoyez:
```
CrÃ©er une API REST simple avec Express
```

### Via CLI

```bash
npm run dev "CrÃ©er une API REST simple avec Express"
```

### Ce qui va se passer

1. L'agent analyse la demande (5-10s)
2. CrÃ©e la structure du projet
3. Vous demande d'approuver `npm install` via WhatsApp
4. GÃ©nÃ¨re le code
5. Fait un commit Git
6. Vous notifie quand c'est terminÃ©

### RÃ©sultat

Nouveau projet dans `workspace/project-xxxxx/` avec:
- âœ… Structure Express complÃ¨te
- âœ… TypeScript configurÃ©
- âœ… Git initialisÃ©
- âœ… README.md
- âœ… PrÃªt Ã  lancer!

## ğŸ§ª Tester le Projet CrÃ©Ã©

```bash
# Aller dans le projet
cd workspace/project-xxxxx

# Installer et lancer
npm install
npm run dev
```

Ouvrez http://localhost:3000 - Votre API fonctionne! ğŸ‰

## ğŸ“‹ Commandes Utiles

### WhatsApp
- `status` - Voir le statut
- `liste` - Approbations en attente
- `approuve <id>` - Approuver
- `refuse <id>` - Rejeter
- `aide` - Afficher l'aide

### CLI
```bash
npm run cli status              # Statut
npm run cli list-tasks          # TÃ¢ches
npm run cli list-projects       # Projets
npm run cli list-approvals      # Approbations
npm run cli approve <id>        # Approuver
npm run cli logs                # Logs
```

## ğŸ¨ Exemples de Demandes

### API Backend
```
CrÃ©er une API REST avec Express pour gÃ©rer des produits (CRUD)
```

### Application React
```
CrÃ©er une app React avec Vite, page d'accueil et routing
```

### Script Python
```
CrÃ©er un script Python pour analyser des fichiers CSV
```

### Full-Stack
```
CrÃ©er une appli full-stack: backend Express + frontend React pour un blog
```

## âš™ï¸ Configuration Rapide

### Si vous avez seulement 8GB RAM

Dans `.env`:
```env
OLLAMA_MODEL=phi3:mini
LLM_MAX_TOKENS=1536
```

Dans `config/agent.config.json`:
```json
{
  "maxConcurrentTasks": 1,
  "enableLLMCache": true
}
```

### Mode Sans WhatsApp

Dans `.env`:
```env
WHATSAPP_ENABLED=false
```

Approuvez via CLI:
```bash
npm run cli list-approvals
npm run cli approve <id>
```

### Mode DÃ©veloppement (Plus Permissif)

Dans `config/permissions.json`:
```json
{
  "criticalActions": {
    "delete": false,
    "execute": false,
    "apiCall": false
  }
}
```

âš ï¸ **Attention:** N'utilisez PAS en production!

## ğŸ”§ DÃ©pannage Express

### "Model not found"
```bash
ollama pull phi3:mini
```

### "Ollama connection refused"
```bash
# VÃ©rifier qu'Ollama tourne
ollama list

# Ou le dÃ©marrer
ollama serve
```

### "WhatsApp QR expired"
```bash
# Supprimer la session et redÃ©marrer
rm -rf whatsapp-session
npm run dev
```

### "Permission denied"
```bash
# VÃ©rifier les permissions dans config/permissions.json
npm run cli config
```

## ğŸ“š Documentation ComplÃ¨te

- [README.md](../README.md) - Vue d'ensemble
- [CONFIGURATION.md](../docs/CONFIGURATION.md) - Configuration dÃ©taillÃ©e
- [WHATSAPP_SETUP.md](../docs/WHATSAPP_SETUP.md) - Setup WhatsApp
- [ARCHITECTURE.md](../docs/ARCHITECTURE.md) - Architecture technique
- [USAGE.md](USAGE.md) - Exemples d'utilisation

## ğŸ“ Prochaines Ã‰tapes

1. âœ… Testez avec diffÃ©rents types de projets
2. âœ… Personnalisez les permissions
3. âœ… Ajoutez vos numÃ©ros WhatsApp
4. âœ… Explorez les templates
5. âœ… CrÃ©ez vos propres outils!

## ğŸ’¡ Conseils

- **Soyez spÃ©cifique** dans vos demandes
- **Approuvez rapidement** pour Ã©viter les timeouts
- **VÃ©rifiez les projets** gÃ©nÃ©rÃ©s avant de les utiliser
- **Utilisez Git** pour tracker les changements
- **Consultez les logs** en cas de problÃ¨me

## ğŸ†˜ Besoin d'Aide?

1. Consultez les logs: `npm run cli logs`
2. VÃ©rifiez la config: `npm run cli config`
3. VÃ©rifiez le modÃ¨le: `npm run cli check-model`
4. Lisez la [documentation complÃ¨te](../docs/)

---

## âœ¨ Vous Ãªtes PrÃªt!

Votre agent IA est maintenant opÃ©rationnel. Commencez Ã  crÃ©er des projets automatiquement!

```bash
npm run dev "CrÃ©er mon premier projet automatique!"
```

**Amusez-vous bien!** ğŸš€
